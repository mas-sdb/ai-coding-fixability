--- 
title: "日本語" 
---
### *Fixability × Semantic Transparency = Stable AI-Assisted Coding* 

[🌐 English](/index.md) | [🌐 日本語](/ja/index.md)

AI コーディングは、初回生成の正確さよりも、  
**誤りをどれだけ安定して修正できるか（Fixability）** によって生産性が決まります。  
そしてその修正能力を左右するのが、  
**AI が状況を正しく理解するための情報量と明確さ（Semantic Transparency）** です。

このフレームワークは、  
AI コード生成の安定性を **「Fixability × Semantic Transparency」** という  
2 つの軸で体系的に説明するために設計されています。

---

## 📚 **目次**

- [なぜこのフレームワークが必要か](#-なぜこのフレームワークが必要か)
- [フレームワーク概要](#-フレームワーク概要)
- [次のステップ](#-次のステップ)
- [まとめ](#-まとめ)
- [詳しく知る：背景と9軸診断フレームワーク](#-詳しく知る背景と9軸診断フレームワーク)
- [診断プロンプト](#-診断プロンプト)
- [このフレームワークについて](#-このフレームワークについて)

---

## 🔍 **なぜこのフレームワークが必要か**

### 現場の課題：「AI の挙動調整が生産性を圧迫する」

テクニカルコンサルタント兼開発者の立場で AI コーディングエージェントを活用する中で、以下の課題が見えてきました。

- AI にコードを書かせて削減できた時間 < AI の挙動を調整する時間
- 「個人の経験則（勘）」「プロンプトのおまじない（運）」に依存
- プロジェクト生産性が運任せになり、組織としてスケールしない

この問題を構造的に説明可能にしたいという考えから出発した説明モデルです。

### 根本原因の視点転換

> 「AI が未熟だから間違える」のではなく、  
> **「AI が正しい判断を下すための情報が不十分」**

この視点を持つことで、「何を AI に伝えたから、この結果になったのか」を、  
個人の勘やおまじないではなく、**文脈の設計不備として説明可能**になります。

### 本フレームワークの価値

- ✅ 再現性のあるロジックで安定性を説明できる
- ✅ 誤推論の原因を構造化し、曖昧な "勘" から脱却
- ✅ 対策を体系的に導けるため、改善が属人化しない
- ✅ 技術・モデル変化に強い普遍性がある

---

## 🧩 **フレームワーク概要**

このサイトでは、以下の要素の概要を紹介します。

### **1. 修正容易性（Fixability）**
AI コード生成で大切なのは「一回で正しいコードを出すこと」ではなく、  
**「間違えたときに正しく修正できるかどうか」** です。

修正ループが安定して収束するほど、AI の出力品質と作業スピードが向上します。

### **2. 意味論の透明性（Semantic Transparency）**
AI が正しく修正するには、状況を理解するための材料が必要です：

- どこで失敗したか（エラー内容）
- 実行中に何が起きたか（ログ）
- 期待される動作（テスト結果）
- 使用技術のバージョン・プロジェクト構成
- 入力例・出力例

これらが揃うほど、AI の誤推論が減り、修正ループが安定します。

### **3. Fixability × Semantic Transparency の相互作用**
この 2 つは独立ではなく強く結びついています：

- Semantic Transparency が高い → AI は誤りを正しく理解 → Fixability が高まる
- Semantic Transparency が低い → AI は誤った文脈で修正 → Fixability が低下

つまり、Fixability は AI の能力だけでなく、**Semantic Transparency は人間側の情報設計の問題**。

### **4. AI モデル非依存の診断プロンプト（9軸診断）**
プロジェクトごとに、AI が誤推論しやすいポイントを体系的に洗い出します。

**入力：**
- 言語・バージョン
- 主要ライブラリ
- 実行環境
- アーキテクチャ概要

**出力：**
- AI が誤推論しやすい箇所
- それに対する具体的な対策

---

## 🧪 **診断プロンプト**

プロジェクトの言語・バージョン・ライブラリ・実行環境を入力すると、  
AI が誤推論しやすいポイントと対策を自動で洗い出す  
**AI モデル非依存の診断プロンプト**を提供しています。

👉 **[診断プロンプトを使う](https://github.com/mas-sdb/ai-coding-fixability/blob/main/ja/diagnostic_prompt.md)**

---

## 🚀 **次のステップ**

### **詳細を理解する**
フレームワークの理論的背景と思考プロセスを探索します。

- [評価モデル詳細](https://github.com/mas-sdb/ai-coding-fixability/blob/main/ja/model.md) - 4層・9軸・検証ループの完全説明
- [利用ガイド](https://github.com/mas-sdb/ai-coding-fixability/blob/main/ja/model-usage-guide.md) - フレームワークの使い分け方
- [思考プロセス](https://github.com/mas-sdb/ai-coding-fixability/blob/main/ja/model-thought-process.md) - このモデルが生まれた背景
- [診断サンプル](https://github.com/mas-sdb/ai-coding-fixability/tree/main/ja/samples) - 実例で学ぶ

### **リポジトリ全体を見る**
詳細なドキュメント、診断プロンプト、サンプルは  
GitHub リポジトリで公開しています。

👉 **[GitHub Repository](https://github.com/mas-sdb/ai-coding-fixability)**

---

## 📋 **まとめ**

| ポイント | 説明 |
|---------|------|
| **課題** | AI コード生成の不安定さは「AI の未熟さ」ではなく、文脈情報の欠落が原因 |
| **鍵** | 修正ループの安定性（**Fixability**） |
| **解決策** | 意味論の透明性（**Semantic Transparency**）を高める |
| **診断** | 9軸診断プロンプトでプロジェクトごとのリスクを事前把握 |

「AI をどう使うか」ではなく **「AI と人間の情報のズレ」** を意識することで、  
AI コーディングの生産性と品質を安定的に高めることができます。

---

## 📚 **詳しく知る：背景と9軸診断フレームワーク**

### 背景：なぜこのフレームワークが必要か

AI コーディングエージェントの登場で、AI がコードを生成する時代が来ました。  
しかし、AI が生成したコードがプロジェクトの文脈に合わなかったり、エラー情報を渡しても修正を繰り返して泥沼化するケースが増えています。

このような状況について、こんな声も聞かれます：
- 「AI がまだ未熟だから仕方ない」
- 「プロンプトが悪い」
- 「モデルが進化すれば解決する」

しかし、**「個人の経験則（勘）」や「プロンプトのおまじない（運）」に頼っている限り、プロジェクトの生産性は運任せになり、スケールしません。**

### 設計思想：情報不透明さをエンジニアリングで制御する

本フレームワークの視点：

> AI に完璧を求めるのではなく、  
> AIと人間の間にある「情報の不透明さ」をエンジニアリングで制御下に置く

**誤推論（Mis-inference）の定義：**  
モデルの学習過程の誤りではなく、**推論フェーズにおける文脈選択の誤り**。  
つまり、AI が推論時に、プロジェクトの文脈に適さない知識を選択してしまう現象。

この視点により、「何を AI に伝えたから、この結果になったのか」を、  
個人の勘ではなく、**構造的に説明可能**にできます。

### 9軸診断フレームワーク

AI が誤推論しやすい領域を、以下の **9つの評価軸** で分類しました。  
（9軸は意図的に独立させていません。相互に影響し合う構造になっています）

#### **実務層（Community/Documentation/Practice）**

1. **Community Consistency**  
   コミュニティの実務慣行のばらつきが、AI の文脈選択を誤らせる部分  
   *例：.NET と .NET Framework の混線、ASP.NET MVC と Minimal APIs の流派差*

2. **Documentation Consistency**  
   公式・非公式ドキュメントの不一致が、AI の知識参照を誤らせる部分  
   *例：API ドキュメントの古いバージョン、ブログ記事の非推奨な書き方*

3. **Practice Consistency**  
   実務の揺らぎ（書き方・慣習・構成）が、AI のコード生成を混乱させる部分  
   *例：データベースマイグレーション手順の違い、命名規約のばらつき*

#### **依存関係層（Dependency/API/Ecosystem）**

4. **Dependency Stability**  
   依存ライブラリの更新頻度・破壊的変更が、AI の推論を不安定にする部分  
   *例：Node.js のメジャー版バージョンアップ、Python パッケージの互換性破壊*

5. **API Consistency**  
   API の一貫性の欠如が、AI の誤った呼び出しを誘発する部分  
   *例：同じ機能が複数の方法で実装されている、パラメータ順序が異なる*

6. **Ecosystem Consistency**  
   フレームワーク・ツールチェーン間の差異が、AI の推論を混乱させる部分  
   *例：ビルドツール（Maven/Gradle）、テストフレームワーク（Jest/Vitest）の選択肢*

#### **意味論層（Static/Runtime/Core）**

7. **Static Semantic Service**  
   コンパイル時に AI が参照できる意味論の豊かさ・一貫性  
   *例：型システム、AST、静的解析 API（Roslyn, tsserver など）*

8. **Runtime Semantic Service**  
   実行時に観測できる意味論の安定性・決定性  
   *例：例外、動的型、実行時型情報の有無*

9. **Core Semantic Consistency**  
   言語仕様そのものの一貫性  
   *例：歴史的経緯・後方互換性ポリシー・文化的価値観による意味論の揺らぎ*

### 実例：C# での診断結果

#### **モダン C#（.NET 8 + ASP.NET Core Minimal APIs + EF Core）**

**Community Consistency での誤推論ポイント：**
- 「.NET Framework（レガシー）」と「.NET（現行：.NET 6+）」の文脈が混線しやすい
- ASP.NET Core でも「MVC / Razor Pages / Minimal APIs / gRPC / Worker」など流派が多い
- DI、ログ、設定、HTTP、ORM の定番がありつつも、現場選好が分かれやすい

**AI に与えるべき対策：**
- 使うターゲット（.NET 8、ASP.NET Core Minimal APIs、EF Core、xUnit など）を明示
- 「採用しない流派」も明記
- 依存注入・設定・ログの「採用ライブラリ・採用パターン」を文章で固定

#### **レガシー C#（.NET Framework 4.8.1 + EF6）**

**Community Consistency での誤推論ポイント：**
- 「.NET は現在 .NET が主流」という一般知識に引っ張られる
- .NET Framework 4.8.1 前提（App.config/Web.config、IIS、GAC 等）を無視
- EF6 と EF Core の知識が混在しやすい
- C# 8+（nullable reference types、switch 式など）を当然のように使う

**AI に与えるべき対策：**
- 「.NET Framework 4.8.1 / C# 7.3 / EF6 を厳守（.NET / EF Core は禁止）」を冒頭で明示
- アプリ種別（WinForms/WPF/ASP.NET MVC など）を固定情報として提供
- 採用パターン（DI の有無、Repository パターン有無など）を明文化

**重要な気づき：**  
プロジェクト固有の文脈を詳しく与えるほど、診断が詳しく、対策が実用的になります。

### 長期安定性を重視した設計

本フレームワークが強力な理由：

- **プロジェクト非依存**：特定の技術スタックに依存しない
- **言語非依存**：静的言語・動的言語を統一的に評価
- **AI モデル非依存**：特定の AI モデルに依存しない
- **長期安定性重視**：急速に進化する具体的ツールより、原則を重視

---

## 🧠 **このフレームワークについて**

AI コーディングの安定性を、  
技術・言語仕様・AI モデル・プロジェクト構造の観点から  
体系的に説明するために開発されたフレームワークです。

**著者：** Masaki Honda  
（テクニカルコンサルタント、MS-DOS の頃から 40 年以上のプログラミング経験）

**ライセンス：** MIT License  
自由に使用・改変・配布できます。詳細は [LICENSE](https://github.com/mas-sdb/ai-coding-fixability/blob/main/LICENSE) を参照。

**初版公開：** 2025/12/29  

本フレームワークは思考実験として公開しており、実証的検証は進行中です。  
コミュニティによる拡張・改善を歓迎します。
